#!/usr/bin/env python3
# -*- coding: utf-8 -*-

# -----------------------------------------------------------------------------
# Copyright (c) 2025 IKI CLOUD
# License: MIT (see LICENSE)
#
# POC code provided for evaluation and educational use.
# If you plan to adapt or deploy this in production, please contact IKI CLOUD first: info@iki-cloud.com.
#
# This project uses third-party libraries (e.g., Oracle Python SDKs) under their own licenses.
# Review and comply with all third-party license terms.
# -----------------------------------------------------------------------------

"""
Oracle23aiEmbedding.py
----------------------

Purpose
  - Extract text lines from a PDF (via your TextExtraction.py)
  - Generate an embedding for each line using OCI Generative AI (Cohere embed-multilingual-v3.0)
  - Insert (filename, line-as-text-chunk, embedding) into Oracle 23ai

Important
  - This script writes directly to: GENAI_USER.INSURANCE_POLICY_AI (FILENAME, TEXT_CHUNK, EMBEDDING)
  - EMBEDDING column must be VECTOR(1024, FLOAT32) to match the model output
  - This approach embeds **client-side per line** (bypasses the server-side chunking procedure).
    For production-scale ingestion, prefer batch embedding and/or DB-side chunking + embedding.

Table expected
  CREATE TABLE GENAI_USER.INSURANCE_POLICY_AI (
    ID         NUMBER GENERATED BY DEFAULT AS IDENTITY PRIMARY KEY,
    FILENAME   VARCHAR2(255),
    TEXT_CHUNK CLOB,
    EMBEDDING  VECTOR(1024, FLOAT32)
  );
"""

import os
import sys
import array
import oracledb
import oci

from typing import List, Iterable

# OCI Generative AI Inference client & models
from oci.generative_ai_inference import GenerativeAiInferenceClient
from oci.generative_ai_inference.models import EmbedTextDetails, OnDemandServingMode

# Your local OCR/extraction module
import TextExtraction


# ========= Configuration =========

# --- Oracle DB connection ---
DB_DSN  = "tirocinio-2025:1521/FREEPDB1"
DB_USER = "GENAI_USER"
DB_PASS = "GENAI_USER"

# Target table and model dimensions
TARGET_TABLE = "GENAI_USER.INSURANCE_POLICY_AI"
MODEL_DIM    = 1024  # cohere.embed-multilingual-v3.0 returns 1024-dim embeddings

# --- OCI / Cohere embedding model on OCI GenAI ---
CONFIG_FILE    = "/home/oracle/POC_GENAI_NODELETE/.oci/config"
CONFIG_PROFILE = "DEFAULT"
COMPARTMENT_ID = "ocid1.tenancy.oc1..xxxxx"
ENDPOINT       = "https://inference.generativeai.eu-frankfurt-1.oci.oraclecloud.com"
MODEL_ID       = "cohere.embed-multilingual-v3.0"

# Line selection heuristic (avoid micro-lines/noise)
MIN_CHARS_PER_LINE = 8  # ignore lines shorter than this
SKIP_PREFIX = "==== PAGINA"  # ignore page headers if present in your OCR output


# ========= Helpers =========

def get_db_conn() -> oracledb.Connection:
    """Open a connection to Oracle Database."""
    return oracledb.connect(user=DB_USER, password=DB_PASS, dsn=DB_DSN)

def get_oci_client() -> GenerativeAiInferenceClient:
    """
    Build an OCI Generative AI Inference client from local config.
    Ensure the profile region matches where the model is available (e.g., eu-frankfurt-1).
    """
    cfg = oci.config.from_file(CONFIG_FILE, CONFIG_PROFILE)
    return GenerativeAiInferenceClient(config=cfg, service_endpoint=ENDPOINT)

def normalize_to_lines(text_or_list) -> List[str]:
    """
    Accepts either:
      - a single string with newlines (typical return from TextExtraction.main),
      - OR a list[str] of lines,
    and returns a clean list[str] of non-empty lines.
    """
    if isinstance(text_or_list, str):
        raw_lines = text_or_list.splitlines()
    elif isinstance(text_or_list, list):
        raw_lines = [s for s in text_or_list if isinstance(s, str)]
    else:
        raise TypeError("TextExtraction.main() must return str or list[str].")

    # Trim and filter noise/empty lines
    out = []
    for ln in raw_lines:
        if not ln:
            continue
        ln = ln.strip()
        if not ln:
            continue
        if SKIP_PREFIX and ln.startswith(SKIP_PREFIX):
            continue
        if len(ln) < MIN_CHARS_PER_LINE:
            continue
        out.append(ln)
    return out

def embed_single_line(client: GenerativeAiInferenceClient, text: str) -> array.array:
    """
    Calls OCI Generative AI to embed a single line of text.
    Returns an array('f', ...) suitable for inserting into VECTOR(1024, FLOAT32).

    The response schema may differ by SDK version:
      - resp.data.embeddings[0].values
      - resp.data.embeddings[0].embedding
      - resp.data.embeddings[0] (list)
    We handle all cases robustly.
    """
    details = EmbedTextDetails(
        serving_mode=OnDemandServingMode(model_id=MODEL_ID),
        inputs=[text],                     # single input
        compartment_id=COMPARTMENT_ID,
        # truncate="NONE",                 # Optional; include if supported in your SDK build
    )
    resp = client.embed_text(details)

    emb = resp.data.embeddings[0]
    if hasattr(emb, "values"):
        emb = emb.values
    elif hasattr(emb, "embedding"):
        emb = emb.embedding
    elif isinstance(emb, list):
        pass  # already a list
    else:
        raise RuntimeError("Unknown embedding format in OCI response.")

    # Ensure float32 array
    vec = array.array("f", [float(x) for x in emb])

    # Sanity check for dimension mismatch
    if MODEL_DIM and len(vec) != MODEL_DIM:
        raise ValueError(f"Embedding dimension mismatch: got {len(vec)}, expected {MODEL_DIM}")

    return vec


# ========= Main logic =========

def process_pdf(pdf_path: str) -> int:
    """
    Extract lines from the PDF, embed each line, and insert rows into TARGET_TABLE.

    Inserts:
      - FILENAME: basename of the PDF
      - TEXT_CHUNK: the line text
      - EMBEDDING: VECTOR(1024, FLOAT32)

    Returns:
      Number of inserted rows.
    """
    if not os.path.exists(pdf_path):
        raise FileNotFoundError(f"PDF not found: {pdf_path}")

    # 1) Extract (string or list[str]) and normalize to lines
    extracted = TextExtraction.main(pdf_path)
    lines = normalize_to_lines(extracted)
    if not lines:
        print(f"[WARN] No usable lines found in: {pdf_path}")
        return 0

    # 2) Prepare clients
    client = get_oci_client()
    conn = get_db_conn()

    inserted = 0
    try:
        with conn.cursor() as cur:
            for line in lines:
                # 3) Embed the line
                try:
                    vec = embed_single_line(client, line)
                except Exception as e:
                    # Skip problematic lines but continue processing
                    print(f"[WARN] Embedding failed for line (skipped): {e}\n  -> {line[:120]}")
                    continue

                # 4) Insert into target table
                cur.execute(
                    f"""
                    INSERT INTO {TARGET_TABLE} (FILENAME, TEXT_CHUNK, EMBEDDING)
                    VALUES (:fn, :txt, :emb)
                    """,
                    dict(fn=os.path.basename(pdf_path), txt=line, emb=vec),
                )
                inserted += 1

        conn.commit()
    finally:
        conn.close()

    print(f"[OK] Inserted {inserted} rows from {os.path.basename(pdf_path)} into {TARGET_TABLE}")
    return inserted


# ========= CLI =========

if __name__ == "__main__":
    if len(sys.argv) != 2:
        print("Usage: python Oracle23aiEmbedding.py <file.pdf>")
        raise SystemExit(1)

    process_pdf(sys.argv[1])

